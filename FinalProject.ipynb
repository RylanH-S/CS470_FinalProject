{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bESTt_23xNeP"
      },
      "source": [
        "Email Spam Classification\n",
        "Rylan Harris\n",
        "\n",
        "Details about the dataset: https://www.kaggle.com/datasets/colormap/spambase/data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libararies and Data"
      ],
      "metadata": {
        "id": "EnXpVAe2uEkI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uwkoHunAwxDl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "d397a61d-8183-43b3-fc03-0a2e740a2732"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "0            0.00               0.64           0.64           0.0   \n",
              "1            0.21               0.28           0.50           0.0   \n",
              "2            0.06               0.00           0.71           0.0   \n",
              "3            0.00               0.00           0.00           0.0   \n",
              "4            0.00               0.00           0.00           0.0   \n",
              "\n",
              "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "0           0.32            0.00              0.00                0.00   \n",
              "1           0.14            0.28              0.21                0.07   \n",
              "2           1.23            0.19              0.19                0.12   \n",
              "3           0.63            0.00              0.31                0.63   \n",
              "4           0.63            0.00              0.31                0.63   \n",
              "\n",
              "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
              "0             0.00            0.00  ...         0.00        0.000   \n",
              "1             0.00            0.94  ...         0.00        0.132   \n",
              "2             0.64            0.25  ...         0.01        0.143   \n",
              "3             0.31            0.63  ...         0.00        0.137   \n",
              "4             0.31            0.63  ...         0.00        0.135   \n",
              "\n",
              "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
              "0          0.0        0.778        0.000        0.000   \n",
              "1          0.0        0.372        0.180        0.048   \n",
              "2          0.0        0.276        0.184        0.010   \n",
              "3          0.0        0.137        0.000        0.000   \n",
              "4          0.0        0.135        0.000        0.000   \n",
              "\n",
              "   capital_run_length_average  capital_run_length_longest  \\\n",
              "0                       3.756                          61   \n",
              "1                       5.114                         101   \n",
              "2                       9.821                         485   \n",
              "3                       3.537                          40   \n",
              "4                       3.537                          40   \n",
              "\n",
              "   capital_run_length_total  spam  \n",
              "0                       278     1  \n",
              "1                      1028     1  \n",
              "2                      2259     1  \n",
              "3                       191     1  \n",
              "4                       191     1  \n",
              "\n",
              "[5 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4e37aaf-58e4-4475-b953-0ec8baf70001\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4e37aaf-58e4-4475-b953-0ec8baf70001')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4e37aaf-58e4-4475-b953-0ec8baf70001 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4e37aaf-58e4-4475-b953-0ec8baf70001');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e233ea7c-fe25-43f0-91c1-6727dc58a4b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e233ea7c-fe25-43f0-91c1-6727dc58a4b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e233ea7c-fe25-43f0-91c1-6727dc58a4b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "source_dataset"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# This was imported via a connected Google Drive. Importing the data otherwise may be required\n",
        "source_dataset = pd.read_csv(\"/content/drive/MyDrive/CS470/spambase.csv\")\n",
        "source_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Test Data"
      ],
      "metadata": {
        "id": "AO0hRy6ziasU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting into randomly shuffled, evenly split sets for 5-cross validation"
      ],
      "metadata": {
        "id": "RgOGoq-vt2fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT = 5\n",
        "\n",
        "split_data = np.array_split(source_dataset.sample(frac = 1), SPLIT)"
      ],
      "metadata": {
        "id": "ZDxjkt91hbcG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes"
      ],
      "metadata": {
        "id": "SJ8Nl31tZ4sW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My first implementation was based of lectures that I found online and wasn't in line with the type of Naive Bayes system that we covered in class. I believe I implemented everything correctly with the Naive Bayes system though it isn't very well performing so I don't doubt I may have done something wrong."
      ],
      "metadata": {
        "id": "6RxrgVV_Z857"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De9ZuLKjxdfJ"
      },
      "source": [
        "### Naive Bayes ver. 1 (deprecated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uKj7H6XI1ZDZ"
      },
      "outputs": [],
      "source": [
        "# class Naive_Bayes():\n",
        "\n",
        "#     def fit(self, features: np.ndarray, target: np.ndarray) -> None:\n",
        "#         n_samples, n_features = features.shape\n",
        "\n",
        "#         self.classes = np.unique(target)\n",
        "#         n_classes = len(self.classes)\n",
        "\n",
        "#         self.means = np.zeros((n_classes, n_features))\n",
        "#         self.variances = np.zeros((n_classes, n_features))\n",
        "#         self.priors = np.zeros(n_classes)\n",
        "\n",
        "#         for index, group in enumerate(self.classes):\n",
        "#             class_features = features[target == group]\n",
        "\n",
        "#             self.means[index, :] = class_features.mean( axis= 0 )\n",
        "#             self.variances[index, :] = class_features.var( axis= 0 )\n",
        "#             self.priors[index] = class_features.size / float(n_samples)\n",
        "\n",
        "#     def predict(self, input_set: np.ndarray) -> np.array:\n",
        "#         predictions = []\n",
        "\n",
        "#         for input in input_set:\n",
        "\n",
        "#             posteriors = []\n",
        "\n",
        "#             for index, feature in enumerate(self.classes):\n",
        "#                 prior = np.log(self.priors[index])\n",
        "#                 posterior = np.sum(np.log(self.prob_function(index, input)))\n",
        "\n",
        "#                 posteriors.append(posterior + prior)\n",
        "\n",
        "#             predictions.append( self.classes[np.argmax(posteriors)] )\n",
        "\n",
        "#         return np.array(predictions)\n",
        "\n",
        "#     def prob_function(self, class_index, value):\n",
        "#         mean = self.means[class_index]\n",
        "#         variance = self.variances[class_index]\n",
        "\n",
        "#         numerator = np.exp(-((value - mean) ** 2) / (2 * variance))\n",
        "#         denominator = np.sqrt(2 * np.pi * variance)\n",
        "\n",
        "#         return numerator/denominator\n",
        "\n",
        "\n",
        "#     def __str__(self):\n",
        "#         return \"Naive Bayes Model\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive bayes ver. 2\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "RyPFu7DWB3To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PWRAEbm6ZxD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_correction(input_dataset):\n",
        "    return input_dataset[:,:-3].astype(bool)\n",
        "\n",
        "class Naive_Bayes():\n",
        "    def __init__(self, threshold = .5):\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def fit(self, features: np.ndarray, target: np.ndarray) -> None:\n",
        "        n_samples, n_features = features.shape\n",
        "\n",
        "        # adjust features to exclude non-applicable features and get occurence bool instead of frequency\n",
        "        features_adj = data_correction(features)\n",
        "\n",
        "        # calculate overall probability\n",
        "        self.p_c = sum(target) / n_samples\n",
        "        # calculate probability for each feature with Laplace smoothing\n",
        "        self.probabilities = np.apply_along_axis(lambda x: ((sum(x) + 1) / (n_samples + 1)) , 0, features_adj)\n",
        "\n",
        "    def predict_prob(self, input_set: np.ndarray) -> np.array:\n",
        "        input_adj = data_correction(input_set)\n",
        "\n",
        "        predictions = np.apply_along_axis(lambda x: np.prod( self.probabilities[x] / self.p_c ),\n",
        "                                          1, input_adj)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict(self, input_set: np.ndarray) -> np.array:\n",
        "        y_prob = self.predict_prob(input_set)\n",
        "        return np.array([1 if prob > self.threshold else 0 for prob in y_prob])\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Naive Bayes Model\""
      ],
      "metadata": {
        "id": "8DRROxf8B-Qg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1fj4UylxlYk"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I never quite got this to function properly with performance feedback but it seems to function well despite that. There is some issue with warnings from the sigmoid function getting values that are too large and I'm not sure how to address that. Overall, I think this implementation is satisfactory but not quick how you had wanted us to make it."
      ],
      "metadata": {
        "id": "PFMImOPtX5uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I think there's some problem with this because it regularly throws warnings\n",
        "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "class LogReg:\n",
        "    def __init__(self, learning_rate = 0.001, n_iters=10000, threshold = .5):\n",
        "        self.learning_rate: float = learning_rate\n",
        "        self.n_iters: int = n_iters\n",
        "        self.weights: np.ndarray  = None\n",
        "        self.pred_prob: np.ndarray  = None\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def fit(self, features: np.ndarray, target: np.ndarray) -> None:\n",
        "        n_samples, n_features = features.shape\n",
        "        X: np.ndarray = np.c_[np.ones_like(target), features]\n",
        "\n",
        "        self.weights = np.random.randn(n_features + 1)\n",
        "        best_performance = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            pred_y = self.predict_prob(features)\n",
        "\n",
        "            gradient_M = (2 / n_samples) * np.dot((pred_y - target), X)\n",
        "\n",
        "            # not currently performance dependent\n",
        "            # performance = calculate_f1_score(confusion_matrix(pred_y, target))\n",
        "\n",
        "            # if performance > best_performance:\n",
        "            #     best_performance = performance\n",
        "            #     self.best_weights = self.weights\n",
        "\n",
        "            self.weights = self.weights - (self.learning_rate * gradient_M)\n",
        "\n",
        "    def predict_prob(self, input: np.ndarray) -> np.ndarray:\n",
        "        X: np.ndarray = np.c_[np.ones(input.shape[0]), input]\n",
        "        return sigmoid(np.dot(X, self.weights))\n",
        "\n",
        "    def predict(self, input: np.ndarray) -> np.ndarray:\n",
        "        X: np.ndarray = np.c_[np.ones(input.shape[0]), input]\n",
        "        y_prob = self.predict_prob(input)\n",
        "        return np.array([1 if prob > self.threshold else 0 for prob in y_prob])\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Logistic Regression Model\""
      ],
      "metadata": {
        "id": "NEyXPKsjnotq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM-bEZUwxlzt"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I likely made a mistake in how I'm using cosine similarity so it doesn't work and I just fell back on using euclidean distance instead. I could definitely refine doing the majority rule counting of the nearest neighbors but left this as is because it works. I'm sure there is something I could improve here to make it perform a bit more quickly as it is clearly the slowest classifier here but I imagine some amount of that is unavoidable."
      ],
      "metadata": {
        "id": "KYeRastFXiIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3_ZDQmpN1b3f"
      },
      "outputs": [],
      "source": [
        "def calculate_distance(input1: float, input2: float) -> float:\n",
        "    return np.sqrt( np.sum((input1 - input2) ** 2) )\n",
        "\n",
        "def calc_distance_cos(input1, input2):\n",
        "    return np.dot(input1, input2)/(np.linalg.norm(input1)*np.linalg.norm(input2))\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=5, threshold = .5):\n",
        "        self.k = k\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def fit(self, features: np.ndarray, target: np.ndarray) -> None:\n",
        "        self.X = features\n",
        "        self.Y = target\n",
        "\n",
        "    def predict_prob(self, input_set: np.ndarray) -> np.array:\n",
        "        predictions = []\n",
        "\n",
        "        for input in input_set:\n",
        "\n",
        "            # calculate distances, I am using euclidean because I either made\n",
        "            # some mistake in cosine similarity (likely) or it just works worse\n",
        "            distances = np.array([calculate_distance(input, x) for x in self.X])\n",
        "\n",
        "            # get the closests k\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "            k_labels = [self.Y[k] for k in k_indices]\n",
        "\n",
        "            # get label with majority vote\n",
        "            unique_labels, counts = np.unique(k_labels, return_counts = True)\n",
        "\n",
        "            counts_dict: dict = dict()\n",
        "            for index, label in enumerate(unique_labels):\n",
        "                counts_dict.update({label: counts[index]})\n",
        "\n",
        "            if 1 in counts_dict.keys():\n",
        "                predictions.append( counts_dict[1] / self.k )\n",
        "            else:\n",
        "                predictions.append( 0 )\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict(self, input_set: np.ndarray) -> np.array:\n",
        "        y_prob = self. predict_prob(input_set)\n",
        "        return np.array([1 if prob > self.threshold else 0 for prob in y_prob])\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"K Nearest Neighbors Model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rABOPaGGyCEy"
      },
      "source": [
        "## Performance Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I had to do some janky patchwork to get the f1 score to work when the classifier predicted all to be one of the classes. That could definitely be improved. I also didn't find a great resource for how to implement ROC_AUC so I didn't implement that."
      ],
      "metadata": {
        "id": "go8hJU5wbf1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_actual):\n",
        "    return np.sum(y_pred==y_actual)/len(y_actual)\n",
        "\n",
        "def confusion_matrix(y_pred: np.ndarray, y_actual: np.ndarray):\n",
        "    y_actu = pd.Series(y_actual, name='Actual')\n",
        "    y_pred = pd.Series(y_pred, name='Predicted')\n",
        "\n",
        "    return pd.crosstab(y_actu, y_pred)\n",
        "\n",
        "def target_split(input_dataset, target_col = \"spam\"):\n",
        "    target = input_dataset[target_col].to_numpy()\n",
        "    features = input_dataset.loc[:, input_dataset.columns != target_col].to_numpy()\n",
        "\n",
        "    return features, target\n",
        "\n",
        "def calculate_f1_score(conf_matrix):\n",
        "    tn = conf_matrix[0][0]\n",
        "    fn = conf_matrix[0][1]\n",
        "\n",
        "    # this isn't guaranteed to work\n",
        "    if (conf_matrix.shape[1] > 1):\n",
        "        fp = conf_matrix[1][0]\n",
        "        tp = conf_matrix[1][1]\n",
        "    else:\n",
        "        fp = 0\n",
        "        tp = 0\n",
        "\n",
        "    return (2* tp) / (2 * tp + fp + fn)\n",
        "\n",
        "# couldn't figure out the methodology for this\n",
        "def calculate_roc_auc(y_pred: np.ndarray, y_actual: np.ndarray):\n",
        "    pass\n",
        "\n",
        "def calculate_metrics(y_pred: np.ndarray, y_actual: np.ndarray):\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_pred, y_actual)\n",
        "    print(conf_matrix)\n",
        "\n",
        "    f1_score = calculate_f1_score(conf_matrix)\n",
        "\n",
        "    print(f\"\\nf1 score: {f1_score}\")\n",
        "\n",
        "    print(f\"Accuracy: {accuracy(y_pred, y_actual)}\\n\")\n",
        "\n",
        "methods  = [Naive_Bayes, LogReg, KNN]"
      ],
      "metadata": {
        "id": "VvoE8bn0EaHr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "Se-ubQLBcRaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I iterate through each testing/training split and the through each method and display the results of those models here."
      ],
      "metadata": {
        "id": "W5S59PMBcT8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q6HKkNhY1fYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882a73ae-0fc9-4711-f346-9a992e4bca27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set 1\n",
            "----------------\n",
            "\n",
            "Naive Bayes Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          420  129\n",
            "1          303   69\n",
            "\n",
            "f1 score: 0.24210526315789474\n",
            "Accuracy: 0.5309446254071661\n",
            "\n",
            "Logistic Regression Model \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5bcb4cc2aa0c>:3: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted    0    1\n",
            "Actual             \n",
            "0          170  379\n",
            "1            6  366\n",
            "\n",
            "f1 score: 0.6553267681289168\n",
            "Accuracy: 0.5819761129207384\n",
            "\n",
            "K Nearest Neighbors Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          469   80\n",
            "1           90  282\n",
            "\n",
            "f1 score: 0.7683923705722071\n",
            "Accuracy: 0.8154180238870793\n",
            "\n",
            "Test Set 2\n",
            "----------------\n",
            "\n",
            "Naive Bayes Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          440  109\n",
            "1          296   75\n",
            "\n",
            "f1 score: 0.2702702702702703\n",
            "Accuracy: 0.5597826086956522\n",
            "\n",
            "Logistic Regression Model \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5bcb4cc2aa0c>:3: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted    0    1\n",
            "Actual             \n",
            "0          421  128\n",
            "1           34  337\n",
            "\n",
            "f1 score: 0.80622009569378\n",
            "Accuracy: 0.8239130434782609\n",
            "\n",
            "K Nearest Neighbors Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          459   90\n",
            "1           96  275\n",
            "\n",
            "f1 score: 0.7472826086956522\n",
            "Accuracy: 0.7978260869565217\n",
            "\n",
            "Test Set 3\n",
            "----------------\n",
            "\n",
            "Naive Bayes Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          402  144\n",
            "1          299   75\n",
            "\n",
            "f1 score: 0.25295109612141653\n",
            "Accuracy: 0.5184782608695652\n",
            "\n",
            "Logistic Regression Model \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5bcb4cc2aa0c>:3: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted    0    1\n",
            "Actual             \n",
            "0          242  304\n",
            "1            7  367\n",
            "\n",
            "f1 score: 0.7023923444976077\n",
            "Accuracy: 0.6619565217391304\n",
            "\n",
            "K Nearest Neighbors Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          452   94\n",
            "1           94  280\n",
            "\n",
            "f1 score: 0.7486631016042781\n",
            "Accuracy: 0.7956521739130434\n",
            "\n",
            "Test Set 4\n",
            "----------------\n",
            "\n",
            "Naive Bayes Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          424  133\n",
            "1          289   74\n",
            "\n",
            "f1 score: 0.2596491228070175\n",
            "Accuracy: 0.5413043478260869\n",
            "\n",
            "Logistic Regression Model \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5bcb4cc2aa0c>:3: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted    0   1\n",
            "Actual            \n",
            "0          539  18\n",
            "1          306  57\n",
            "\n",
            "f1 score: 0.2602739726027397\n",
            "Accuracy: 0.6478260869565218\n",
            "\n",
            "K Nearest Neighbors Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          473   84\n",
            "1          105  258\n",
            "\n",
            "f1 score: 0.7319148936170212\n",
            "Accuracy: 0.7945652173913044\n",
            "\n",
            "Test Set 5\n",
            "----------------\n",
            "\n",
            "Naive Bayes Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          466  121\n",
            "1          276   57\n",
            "\n",
            "f1 score: 0.22309197651663404\n",
            "Accuracy: 0.5684782608695652\n",
            "\n",
            "Logistic Regression Model \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5bcb4cc2aa0c>:3: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted    0   1\n",
            "Actual            \n",
            "0          570  17\n",
            "1          289  44\n",
            "\n",
            "f1 score: 0.2233502538071066\n",
            "Accuracy: 0.6673913043478261\n",
            "\n",
            "K Nearest Neighbors Model \n",
            "\n",
            "Predicted    0    1\n",
            "Actual             \n",
            "0          495   92\n",
            "1           87  246\n",
            "\n",
            "f1 score: 0.7332339791356185\n",
            "Accuracy: 0.8054347826086956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for index, testing_set in enumerate(split_data):\n",
        "    print(f\"Test Set {index + 1}\\n----------------\\n\")\n",
        "\n",
        "    training_set = source_dataset.drop(testing_set.index)\n",
        "\n",
        "    training_features, training_target = target_split(training_set)\n",
        "    testing_features, testing_target = target_split(testing_set)\n",
        "\n",
        "    for method in methods:\n",
        "        classifier = method()\n",
        "        print(classifier, \"\\n\")\n",
        "\n",
        "        classifier.fit( training_features, training_target )\n",
        "        prediction = classifier.predict( testing_features )\n",
        "\n",
        "        calculate_metrics(prediction, testing_target)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "De9ZuLKjxdfJ",
        "o_RK5JqK_L85"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}